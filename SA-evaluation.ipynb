{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4645f6d1",
   "metadata": {},
   "source": [
    "# Training a perceptron classifier on movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222a20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import gzip\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29342ec8",
   "metadata": {},
   "source": [
    "## Movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe64b0",
   "metadata": {},
   "source": [
    "### Reading word vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234e1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Perceptron classifier on word2vec embeddings\n",
    "\n",
    "# get document representations\n",
    "# results to be compared with retrofitted vectors\n",
    "\n",
    "\n",
    "# filename: txt file\n",
    "''' Read and normalize the embeddings '''\n",
    "def read_embeddings(filename):\n",
    "    print(\"\\nReading embeddings...\")\n",
    "    # keys: words (string)\n",
    "    # values: normalized vectors (NumPy array)\n",
    "    embeds = {} \n",
    "  \n",
    "    # using encoding='utf-8' to avoid UnicodeEncodeError on some systems\n",
    "    with (gzip.open(filename, 'rt', encoding='utf-8') if filename.endswith('.gz') else open(filename, 'r', encoding='utf-8')) as file:\n",
    "        for line in file:\n",
    "            elements = line.strip().split()\n",
    "            word = elements[0]\n",
    "            vector = np.array([float(value) for value in elements[1:]], dtype=float)\n",
    "        \n",
    "            # normalize vector (Euclidean norm)\n",
    "            norm = np.linalg.norm(vector)\n",
    "            embeds[word] = vector / norm  \n",
    "  \n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c7c1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word, vec in read_word_vecs(\"embeddings/sample_vec.txt\").items():\n",
    "#     print(f\"word: {word}\")\n",
    "#     print(f\"vector: {vec}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc7323",
   "metadata": {},
   "source": [
    "### Converting movie reviews to averaged vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c60b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract reviews from files, convert to review vectors to be stored in numpy matrix (nb review, 250)\n",
    "\n",
    "# word_vectors: dict; filename: txt file; vec_size: int\n",
    "def reviews_to_vecs(word_vectors, filename, vec_size, avg=False):\n",
    "    \"\"\"extract review texts from a file and convert them to averaged word2vec embeddings\"\"\"\n",
    "    \n",
    "    review_vectors = []\n",
    "    Y = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:      \n",
    "        for line in file:\n",
    "            \n",
    "            # initialize empty review vec of given size\n",
    "            review_vec = np.zeros(vec_size, dtype=float)\n",
    "            \n",
    "            line = line.lower().strip().split()\n",
    "            \n",
    "            # normalized/tokenized moview review, gold label\n",
    "            review, y = line[1:], line[0]\n",
    "            Y.append(y)\n",
    "            \n",
    "            # normalized/tokenized moview review\n",
    "            #review = line.split()[1:]\n",
    "            \n",
    "            for word in review:\n",
    "                if word in word_vectors:\n",
    "                    review_vec += word_vectors[word]\n",
    "            \n",
    "            if avg:\n",
    "                # get average of word vectors by dividing sum by nb of words in review\n",
    "                review_vec /= len(review)\n",
    "            \n",
    "            review_vectors.append(review_vec)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    X = np.array(review_vectors)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X, Y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37c4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "[[ 0.0389759  -0.01411923  0.00649187 ...  0.02806024  0.00548851\n",
      "   0.03144906]\n",
      " [ 0.06330879  0.01469497  0.01734737 ...  0.02479514  0.02445976\n",
      "   0.03876584]\n",
      " [ 0.05804809  0.00525672  0.01786497 ...  0.03130196  0.01622859\n",
      "   0.04347507]\n",
      " [ 0.04500404  0.02146169  0.01359256 ...  0.04601991  0.04227773\n",
      "   0.07036946]\n",
      " [ 0.04966516  0.00886954  0.01860892 ...  0.02242932  0.01846929\n",
      "   0.05119996]]\n",
      "Shape: (6920, 250)\n",
      "\n",
      "['1' '1' '1' '1' '1']\n",
      "Shape: (6920,)\n"
     ]
    }
   ],
   "source": [
    "word_vectors = read_embeddings(\"embeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean.gz\")\n",
    "\n",
    "# getting train data\n",
    "X_train, Y_train = reviews_to_vecs(word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=True)\n",
    "\n",
    "print(X_train[:5])\n",
    "print(f\"Shape: {X_train.shape}\\n\")\n",
    "\n",
    "print(Y_train[:5])\n",
    "print(f\"Shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e585a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08391141  0.00493503  0.0007743  ...  0.02950124  0.00507889\n",
      "   0.06420889]\n",
      " [ 0.05613794  0.02151759  0.00791124 ...  0.02658185  0.00703825\n",
      "   0.05526056]\n",
      " [ 0.06949902  0.05778605 -0.00777598 ...  0.01285677  0.0061893\n",
      "   0.06091437]\n",
      " [ 0.05763503 -0.00330982  0.00640642 ...  0.03454663  0.02482536\n",
      "   0.07949062]\n",
      " [ 0.07521693  0.01980447  0.01480978 ...  0.01391576  0.02573809\n",
      "   0.06107445]]\n",
      "Shape: (1821, 250)\n",
      "\n",
      "['1' '1' '1' '1' '1']\n",
      "Shape: (1821,)\n"
     ]
    }
   ],
   "source": [
    "# getting test data\n",
    "X_test, Y_test = reviews_to_vecs(word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=True)\n",
    "\n",
    "print(X_test[:5])\n",
    "print(f\"Shape: {X_test.shape}\\n\")\n",
    "\n",
    "print(Y_test[:5])\n",
    "print(f\"Shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6ada3",
   "metadata": {},
   "source": [
    "## Training a `sklearn` Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31b360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy (original averaged embeddings):  76.94%\n"
     ]
    }
   ],
   "source": [
    "# using pretrained vectors (using average)\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(f\"Perceptron accuracy (original averaged embeddings): {clf.score(X_test, Y_test): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8067483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy (original summed embeddings):  68.86%\n"
     ]
    }
   ],
   "source": [
    "# using pretrained vectors (using sum)\n",
    "X_train, Y_train = reviews_to_vecs(word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=False)\n",
    "X_test, Y_test = reviews_to_vecs(word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=False)\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(f\"Perceptron accuracy (original summed embeddings): {clf.score(X_test, Y_test): .2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeae3a3",
   "metadata": {},
   "source": [
    "## Using our retrofitted vectors from `shafiabadi-duignan-modified.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04007a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (averaged) with the PPDB:  79.90%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with the ppdb (averaged)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_ppdb_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=True)\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with the PPDB: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "252066a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with the PPDB:  74.90%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with the ppdb (summed)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_ppdb_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=False)\n",
    "\n",
    "clf = Perceptron()\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with the PPDB: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25e95dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (averaged) with WN synonyms:  79.90%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with wn synonyms (averaged)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_wn_syn_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=True)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with WN synonyms: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a6b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with WN synonyms:  78.03%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with wn synonyms (summed)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_wn_syn_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=False)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with WN synonyms: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d3876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (averaged) with WN (all relations):  76.61%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with wn synonyms, hypernyms and hyponyms (averaged)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_wn_all_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=True)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with WN (all relations): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1e6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with WN (all relations):  77.27%\n"
     ]
    }
   ],
   "source": [
    "# using our vectors retrofitted with wn synonyms, hypernyms and hyponyms (summed)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_wn_all_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_train.txt', vec_size=250, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'datasets/stanford_raw_test.txt', vec_size=250, avg=False)\n",
    "\n",
    "clf = Perceptron()\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with WN (all relations): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf94547",
   "metadata": {},
   "source": [
    "## Testing French word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a85faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tweets\n",
    "french_data = pd.read_csv('datasets/french_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cfd5234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oui, cela fonctionne mieux que de l'attendre Ã  la fin, je me demande si j'ai le temps de suivre un bon blog.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = french_data.iloc[:, 1], french_data.iloc[:, 0]\n",
    "y[1526719]  \n",
    "X[1526719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d5d8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "# write data to file\n",
    "def write_reviews(X, y, path):\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        for label, review in (zip(y, X)):\n",
    "            # padding punct with whitespaces\n",
    "            line = f\"{label} {review}\\n\"\n",
    "            line = re.sub('([:;\\\".,!?()])', r' \\1 ', line)\n",
    "            line = re.sub('\\s{2,}', ' ', line)\n",
    "            \n",
    "            # add white space after apostrophe\n",
    "            line = re.sub('([A-z]\\')', r'\\1 ', line)\n",
    "            file.write(line)\n",
    "   \n",
    "    print(f\"Reviews successfully written to {path}\")\n",
    "\n",
    "path_train = 'datasets/french_tweets_train.txt'\n",
    "path_test = 'datasets/french_tweets_test.txt'\n",
    "\n",
    "write_reviews(X_train, y_train, path_train)\n",
    "write_reviews(X_test, y_test, path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53fa333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# french movie reviews\n",
    "# french_movie_reviews_train = pd.read_csv('datasets/french_movie_reviews_train.csv')\n",
    "# french_movie_reviews_test = pd.read_csv('datasets/french_movie_reviews_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ab6b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# french_movie_reviews_train\n",
    "\n",
    "# X_train, y_train = french_movie_reviews_train.iloc[:, 2], french_movie_reviews_train.iloc[:, 3]\n",
    "# X_test, y_test = french_movie_reviews_test.iloc[:, 2], french_movie_reviews_test.iloc[:, 3]\n",
    "\n",
    "# path_train = 'datasets/french_movie_reviews_train.txt'\n",
    "# path_test = 'datasets/french_movie_reviews_test.txt'\n",
    "\n",
    "# write_reviews(X_train, y_train, path_train)\n",
    "# write_reviews(X_test, y_test, path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7028522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of French pretrained embeddings (averaged):  53.47%\n"
     ]
    }
   ],
   "source": [
    "# testing pretrained vectors\n",
    "word_vectors_pretrain_fr = read_embeddings(\"embeddings/vecs100-linear-frwiki\")\n",
    "X_train_pretrain, Y_train_pretrain = reviews_to_vecs(word_vectors_pretrain_fr, path_train, vec_size=100, avg=True)\n",
    "X_test_pretrain, Y_test_pretrain = reviews_to_vecs(word_vectors_pretrain_fr, path_test, vec_size=100, avg=True)\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_pretrain, Y_train_pretrain)\n",
    "\n",
    "print(f\"Perceptron accuracy of French pretrained embeddings (averaged): {clf.score(X_test_pretrain, Y_test_pretrain): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8a5f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of French pretrained embeddings (summed):  63.70%\n"
     ]
    }
   ],
   "source": [
    "# testing pretrained vectors\n",
    "word_vectors_pretrain_fr = read_embeddings(\"embeddings/vecs100-linear-frwiki\")\n",
    "X_train_pretrain, Y_train_pretrain = reviews_to_vecs(word_vectors_pretrain_fr, path_train, vec_size=100, avg=False)\n",
    "X_test_pretrain, Y_test_pretrain = reviews_to_vecs(word_vectors_pretrain_fr, path_test, vec_size=100, avg=False)\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_pretrain, Y_train_pretrain)\n",
    "\n",
    "print(f\"Perceptron accuracy of French pretrained embeddings (summed): {clf.score(X_test_pretrain, Y_test_pretrain): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97b5c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (averaged) with WN (syn):  61.50%\n"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with wn synonyms (averaged)\n",
    "retrofitted_word_vectors_fr = read_embeddings(\"embeddings/out_retrofitted_fr_wn_syn_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_train, vec_size=100, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_test, vec_size=100, avg=True)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with WN (syn): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea78a7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with WN (syn):  56.96%\n"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with wn synonyms (summed)\n",
    "retrofitted_word_vectors_fr = read_embeddings(\"embeddings/out_retrofitted_fr_wn_syn_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_train, vec_size=100, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_test, vec_size=100, avg=False)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with WN (syn): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cf62ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (averaged) with WN (all):  61.40%\n"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with wn synonyms, hyponyms and hypernyms (averaged)\n",
    "retrofitted_word_vectors_fr = read_embeddings(\"embeddings/out_retrofitted_fr_wn_all_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_train, vec_size=100, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_test, vec_size=100, avg=True)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with WN (all): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1461b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with WN (all):  62.48%\n"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with wn synonyms, hyponyms and hypernyms (summed)\n",
    "retrofitted_word_vectors_fr = read_embeddings(\"embeddings/out_retrofitted_fr_wn_all_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_train, vec_size=100, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors_fr, path_test, vec_size=100, avg=False)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with WN (all): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c80e22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# using our french vectors retrofitted with the ppdb (averaged)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m retrofitted_word_vectors \u001b[39m=\u001b[39m read_embeddings(\u001b[39m\"\u001b[39m\u001b[39membeddings/out_retrofitted_fr_ppdb_100.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train_retrofit, Y_train_retrofit \u001b[39m=\u001b[39m reviews_to_vecs(retrofitted_word_vectors, path_train, vec_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, avg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m X_test_retrofit, Y_test_retrofit \u001b[39m=\u001b[39m reviews_to_vecs(retrofitted_word_vectors, path_test, vec_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, avg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m clf \u001b[39m=\u001b[39m Perceptron(tol\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_train' is not defined"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with the ppdb (averaged)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_fr_ppdb_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, path_train, vec_size=100, avg=True)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, path_test, vec_size=100, avg=True)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (averaged) with the PPDB: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2000b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading embeddings...\n",
      "Reading embeddings done!\n",
      "Perceptron accuracy of retrofitted embeddings (summed) with the PPDB:  64.40%\n"
     ]
    }
   ],
   "source": [
    "# using our french vectors retrofitted with the ppdb (summed)\n",
    "retrofitted_word_vectors = read_embeddings(\"embeddings/out_retrofitted_fr_ppdb_100.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, path_train, vec_size=100, avg=False)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, path_test, vec_size=100, avg=False)\n",
    "\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy of retrofitted embeddings (summed) with the PPDB: {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
