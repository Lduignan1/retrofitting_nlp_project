{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9671f233",
   "metadata": {},
   "source": [
    "# Training a perceptron classifier on movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec900590",
   "metadata": {},
   "source": [
    "## Testing `Perceptron()` using generic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3a19acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "decdf4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393433500278241"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron()\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb4005b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  0.  0.  0.]\n",
      " [ 0.  0. 10. ...  0.  0.  0.]\n",
      " [ 0.  0.  6. ... 13. 11.  1.]]\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X[:20])\n",
    "print(y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f5cffbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709d681",
   "metadata": {},
   "source": [
    "## Movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30282941",
   "metadata": {},
   "source": [
    "### Reading word vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "313800e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Perceptron classifier on word2vec embeddings\n",
    "\n",
    "# get document representations\n",
    "# results to be compared with retrofitted vectors\n",
    "\n",
    "# code: faruqui et al. (2015)\n",
    "\n",
    "# filename: txt file\n",
    "def read_word_vecs(filename):\n",
    "    \"\"\" Read all the word vectors and normalize them \"\"\"\n",
    "    word_vectors = {}\n",
    "    #if filename.endswith('.gz'):\n",
    "     #   fileObject = gzip.open(filename, 'r', encoding='utf-8')\n",
    "    #else: fileObject = open(filename, 'r', encoding='utf-8')\n",
    "    with open(filename, 'r', encoding='utf-8') as file:    \n",
    "        for line in file:\n",
    "            \n",
    "            line = line.strip().lower()\n",
    "            word = line.split()[0]\n",
    "            word_vectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "            for index, vec_val in enumerate(line.split()[1:]):\n",
    "                word_vectors[word][index] = float(vec_val)\n",
    "            # normalize weight vector \n",
    "            # a normalized vector points in the same direction as the original \n",
    "            # but has length 1\n",
    "            word_vectors[word] /= math.sqrt((word_vectors[word]**2).sum() + 1e-6)\n",
    "    \n",
    "    #sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82bc3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word, vec in read_word_vecs(\"embeddings/sample_vec.txt\").items():\n",
    "#     print(f\"word: {word}\")\n",
    "#     print(f\"vector: {vec}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d593904",
   "metadata": {},
   "source": [
    "### Converting movie reviews to averaged vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5593ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract reviews from files, convert to review vectors to be stored in numpy matrix (nb review, 250)\n",
    "\n",
    "def reviews_to_vecs(word_vectors, filename, vec_size):\n",
    "    \"\"\"extract review texts from a file and convert them to averaged word2vec embeddings\"\"\"\n",
    "    \n",
    "    review_vectors = []\n",
    "    Y = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:      \n",
    "        for line in file:\n",
    "            \n",
    "            # initialize empty review vec of given size\n",
    "            review_vec = np.zeros(vec_size, dtype=float)\n",
    "            \n",
    "            line = line.strip().lower()\n",
    "            \n",
    "            # gold label\n",
    "            y = line.split()[0]\n",
    "            Y.append(y)\n",
    "            \n",
    "            # normalized/tokenized moview review\n",
    "            review = line.split()[1:]\n",
    "            \n",
    "            for word in review:\n",
    "                if word in word_vectors:\n",
    "                    review_vec += word_vectors[word]\n",
    "                    \n",
    "            # get average of word vectors by dividing sum by nb of words in review\n",
    "            review_vec /= len(review)\n",
    "            \n",
    "            review_vectors.append(review_vec)\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    X = np.array(review_vectors)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X, Y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4648b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0389759  -0.01411923  0.00649187 ...  0.02806024  0.00548851\n",
      "   0.03144906]\n",
      " [ 0.06330878  0.01469497  0.01734737 ...  0.02479514  0.02445976\n",
      "   0.03876584]\n",
      " [ 0.05804808  0.00525672  0.01786497 ...  0.03130196  0.01622859\n",
      "   0.04347507]\n",
      " [ 0.04500403  0.02146169  0.01359255 ...  0.04601991  0.04227773\n",
      "   0.07036946]\n",
      " [ 0.04966516  0.00886954  0.01860892 ...  0.02242931  0.01846928\n",
      "   0.05119996]]\n",
      "Shape: (6920, 250)\n",
      "\n",
      "['1' '1' '1' '1' '1']\n",
      "Shape: (6920,)\n"
     ]
    }
   ],
   "source": [
    "word_vectors = read_word_vecs(\"embeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "\n",
    "# getting train data\n",
    "X_train, Y_train = reviews_to_vecs(word_vectors, 'stanford_raw_train.txt', vec_size=250)\n",
    "\n",
    "print(X_train[:5])\n",
    "print(f\"Shape: {X_train.shape}\\n\")\n",
    "\n",
    "print(Y_train[:5])\n",
    "print(f\"Shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74ae9881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08391141  0.00493503  0.0007743  ...  0.02950124  0.00507889\n",
      "   0.06420888]\n",
      " [ 0.05613793  0.02151759  0.00791124 ...  0.02658185  0.00703825\n",
      "   0.05526056]\n",
      " [ 0.06949902  0.05778605 -0.00777598 ...  0.01285676  0.0061893\n",
      "   0.06091437]\n",
      " [ 0.05763503 -0.00330982  0.00640642 ...  0.03454663  0.02482536\n",
      "   0.07949061]\n",
      " [ 0.07521692  0.01980447  0.01480977 ...  0.01391576  0.02573809\n",
      "   0.06107445]]\n",
      "Shape: (1821, 250)\n",
      "\n",
      "['1' '1' '1' '1' '1']\n",
      "Shape: (1821,)\n"
     ]
    }
   ],
   "source": [
    "# getting test data\n",
    "X_test, Y_test = reviews_to_vecs(word_vectors, 'stanford_raw_test.txt', vec_size=250)\n",
    "\n",
    "print(X_test[:5])\n",
    "print(f\"Shape: {X_test.shape}\\n\")\n",
    "\n",
    "print(Y_test[:5])\n",
    "print(f\"Shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fbacf",
   "metadata": {},
   "source": [
    "## Training a `sklearn` Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3eb84a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy (original embeddings):  76.94%\n"
     ]
    }
   ],
   "source": [
    "# using pretrained vectors\n",
    "clf = Perceptron()\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(f\"Perceptron accuracy (original embeddings): {clf.score(X_test, Y_test): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf655479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy (retrofitted embeddings):  79.08%\n"
     ]
    }
   ],
   "source": [
    "# using retrofitted vectors\n",
    "retrofitted_word_vectors = read_word_vecs(\"embeddings/out_faruqui_250.txt\")\n",
    "X_train_retrofit, Y_train_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'stanford_raw_train.txt', vec_size=250)\n",
    "X_test_retrofit, Y_test_retrofit = reviews_to_vecs(retrofitted_word_vectors, 'stanford_raw_test.txt', vec_size=250)\n",
    "\n",
    "clf = Perceptron()\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_retrofit, Y_train_retrofit)\n",
    "\n",
    "print(f\"Perceptron accuracy (retrofitted embeddings): {clf.score(X_test_retrofit, Y_test_retrofit): .2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2103e7",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "- We see a ~2% increase in accuracy compared to Faruqui et al.'s best results\n",
    "- These word vectors were retrofitted using the PPDB lexicon which seems to improve results more than others in this task\n",
    "- We should see similar results with our own retrofitted vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
